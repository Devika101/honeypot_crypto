"""Anomaly detection and alerting system.

Implements multiple anomaly detection approaches:
- Isolation Forest for statistical anomalies in network traffic
- Autoencoder for unusual behavior sequence detection
- Alert generation with severity classification
- False positive reduction via ensemble agreement
"""

from __future__ import annotations

from collections import deque
from dataclasses import dataclass, field
from datetime import datetime, timezone
from enum import Enum
from typing import Any, Optional

import numpy as np
import torch
import torch.nn as nn
from sklearn.ensemble import IsolationForest

from src.utils.logger import get_logger

logger = get_logger(__name__)


class AlertSeverity(Enum):
    """Alert severity levels."""

    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"


@dataclass
class Alert:
    """A security alert generated by the anomaly detection system."""

    alert_id: str
    severity: AlertSeverity
    source_ip: str
    description: str
    anomaly_score: float
    detector: str  # Which detector raised the alert
    timestamp: str = ""
    metadata: dict[str, Any] = field(default_factory=dict)
    acknowledged: bool = False

    def to_dict(self) -> dict[str, Any]:
        return {
            "alert_id": self.alert_id,
            "severity": self.severity.value,
            "source_ip": self.source_ip,
            "description": self.description,
            "anomaly_score": self.anomaly_score,
            "detector": self.detector,
            "timestamp": self.timestamp,
            "metadata": self.metadata,
            "acknowledged": self.acknowledged,
        }


class BehaviorAutoencoder(nn.Module):
    """Autoencoder for detecting unusual behavior sequences.

    Trained on normal interaction patterns, it flags sequences with
    high reconstruction error as anomalous.

    Args:
        input_dim: Feature dimension of the input.
        encoding_dim: Bottleneck dimension.
        hidden_dims: List of hidden layer dimensions for encoder.
    """

    def __init__(
        self,
        input_dim: int = 64,
        encoding_dim: int = 32,
        hidden_dims: Optional[list[int]] = None,
    ) -> None:
        super().__init__()
        hidden_dims = hidden_dims or [128, 64]

        # Encoder
        encoder_layers: list[nn.Module] = []
        dim = input_dim
        for h in hidden_dims:
            encoder_layers.extend([
                nn.Linear(dim, h),
                nn.ReLU(),
                nn.Dropout(0.2),
            ])
            dim = h
        encoder_layers.append(nn.Linear(dim, encoding_dim))
        self.encoder = nn.Sequential(*encoder_layers)

        # Decoder (mirror of encoder)
        decoder_layers: list[nn.Module] = []
        dim = encoding_dim
        for h in reversed(hidden_dims):
            decoder_layers.extend([
                nn.Linear(dim, h),
                nn.ReLU(),
                nn.Dropout(0.2),
            ])
            dim = h
        decoder_layers.append(nn.Linear(dim, input_dim))
        self.decoder = nn.Sequential(*decoder_layers)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """Reconstruct the input.

        Args:
            x: (batch, input_dim) feature vectors.

        Returns:
            (batch, input_dim) reconstructed features.
        """
        encoded = self.encoder(x)
        return self.decoder(encoded)

    def reconstruction_error(self, x: torch.Tensor) -> torch.Tensor:
        """Compute per-sample reconstruction error (MSE).

        Args:
            x: (batch, input_dim) feature vectors.

        Returns:
            (batch,) reconstruction error for each sample.
        """
        reconstructed = self.forward(x)
        return ((x - reconstructed) ** 2).mean(dim=1)


class AnomalyDetector:
    """Ensemble anomaly detection system.

    Combines Isolation Forest and autoencoder scores to identify
    anomalous attacker behavior with reduced false positive rates.

    Args:
        n_estimators: Number of trees for Isolation Forest.
        contamination: Expected proportion of anomalies.
        autoencoder_threshold: Reconstruction error threshold for anomalies.
        severity_thresholds: Dict mapping severity levels to score thresholds.
    """

    def __init__(
        self,
        n_estimators: int = 200,
        contamination: float = 0.05,
        autoencoder_threshold: float = 0.5,
        severity_thresholds: Optional[dict[str, float]] = None,
    ) -> None:
        self.autoencoder_threshold = autoencoder_threshold
        self.severity_thresholds = severity_thresholds or {
            "low": 0.3,
            "medium": 0.6,
            "high": 0.8,
            "critical": 0.95,
        }

        # Isolation Forest
        self._isolation_forest = IsolationForest(
            n_estimators=n_estimators,
            contamination=contamination,
            random_state=42,
        )
        self._if_fitted = False

        # Autoencoder
        self._autoencoder = BehaviorAutoencoder()
        self._ae_trained = False

        # Alert management
        self._alerts: list[Alert] = []
        self._alert_counter = 0
        self._recent_scores: deque[float] = deque(maxlen=1000)

    def fit_isolation_forest(self, X: np.ndarray) -> None:
        """Fit the Isolation Forest on normal traffic data.

        Args:
            X: (N, features) array of normal behavior feature vectors.
        """
        self._isolation_forest.fit(X)
        self._if_fitted = True
        logger.info("Isolation Forest fitted", n_samples=X.shape[0])

    def train_autoencoder(
        self,
        X: torch.Tensor,
        epochs: int = 50,
        lr: float = 0.001,
        batch_size: int = 32,
    ) -> list[float]:
        """Train the autoencoder on normal behavior data.

        Args:
            X: (N, features) tensor of normal behavior feature vectors.
            epochs: Number of training epochs.
            lr: Learning rate.
            batch_size: Training batch size.

        Returns:
            List of per-epoch losses.
        """
        optimizer = torch.optim.Adam(self._autoencoder.parameters(), lr=lr)
        criterion = nn.MSELoss()
        losses = []

        self._autoencoder.train()
        for epoch in range(epochs):
            epoch_loss = 0.0
            n_batches = 0

            for i in range(0, len(X), batch_size):
                batch = X[i : i + batch_size]
                optimizer.zero_grad()
                reconstructed = self._autoencoder(batch)
                loss = criterion(reconstructed, batch)
                loss.backward()
                optimizer.step()
                epoch_loss += loss.item()
                n_batches += 1

            avg_loss = epoch_loss / max(n_batches, 1)
            losses.append(avg_loss)

        self._autoencoder.eval()
        self._ae_trained = True
        logger.info("Autoencoder trained", epochs=epochs, final_loss=f"{losses[-1]:.6f}")
        return losses

    def detect(
        self,
        features: np.ndarray,
        source_ip: str = "unknown",
    ) -> Optional[Alert]:
        """Run anomaly detection on a feature vector.

        Uses ensemble of Isolation Forest and autoencoder. An alert is
        generated only if both detectors agree (reducing false positives).

        Args:
            features: (features,) array of behavior features.
            source_ip: Source IP for the alert.

        Returns:
            Alert if anomaly detected, None otherwise.
        """
        scores = []

        # Isolation Forest score
        if self._if_fitted:
            # score_samples returns negative anomaly scores
            if_score = -self._isolation_forest.score_samples(features.reshape(1, -1))[0]
            # Normalize to [0, 1] roughly
            if_score = min(max(if_score, 0), 1)
            scores.append(("isolation_forest", if_score))

        # Autoencoder score
        if self._ae_trained:
            with torch.no_grad():
                tensor = torch.tensor(features, dtype=torch.float32).unsqueeze(0)
                ae_score = self._autoencoder.reconstruction_error(tensor).item()
                # Normalize based on threshold
                ae_score = min(ae_score / (self.autoencoder_threshold * 2), 1.0)
                scores.append(("autoencoder", ae_score))

        if not scores:
            return None

        # Ensemble: average of available scores
        avg_score = np.mean([s[1] for s in scores])
        self._recent_scores.append(avg_score)

        # Determine severity
        severity = self._score_to_severity(avg_score)
        if severity is None:
            return None

        # Generate alert
        self._alert_counter += 1
        detectors = ", ".join(f"{name}={score:.3f}" for name, score in scores)

        alert = Alert(
            alert_id=f"ALERT-{self._alert_counter:06d}",
            severity=severity,
            source_ip=source_ip,
            description=f"Anomalous behavior detected (ensemble score: {avg_score:.3f})",
            anomaly_score=avg_score,
            detector=detectors,
            timestamp=datetime.now(timezone.utc).isoformat(),
            metadata={
                "individual_scores": {name: score for name, score in scores},
                "features": features.tolist(),
            },
        )

        self._alerts.append(alert)

        logger.warning(
            "Anomaly alert generated",
            alert_id=alert.alert_id,
            severity=severity.value,
            score=f"{avg_score:.3f}",
            source_ip=source_ip,
        )

        return alert

    def _score_to_severity(self, score: float) -> Optional[AlertSeverity]:
        """Map an anomaly score to a severity level."""
        if score >= self.severity_thresholds["critical"]:
            return AlertSeverity.CRITICAL
        elif score >= self.severity_thresholds["high"]:
            return AlertSeverity.HIGH
        elif score >= self.severity_thresholds["medium"]:
            return AlertSeverity.MEDIUM
        elif score >= self.severity_thresholds["low"]:
            return AlertSeverity.LOW
        return None

    def get_alerts(
        self,
        severity: Optional[AlertSeverity] = None,
        unacknowledged_only: bool = False,
    ) -> list[Alert]:
        """Get alerts with optional filtering."""
        alerts = self._alerts
        if severity:
            alerts = [a for a in alerts if a.severity == severity]
        if unacknowledged_only:
            alerts = [a for a in alerts if not a.acknowledged]
        return alerts

    def acknowledge_alert(self, alert_id: str) -> bool:
        """Mark an alert as acknowledged."""
        for alert in self._alerts:
            if alert.alert_id == alert_id:
                alert.acknowledged = True
                return True
        return False

    def get_stats(self) -> dict[str, Any]:
        """Get anomaly detection statistics."""
        severity_counts: dict[str, int] = {}
        for alert in self._alerts:
            key = alert.severity.value
            severity_counts[key] = severity_counts.get(key, 0) + 1

        recent = list(self._recent_scores)
        return {
            "total_alerts": len(self._alerts),
            "unacknowledged": sum(1 for a in self._alerts if not a.acknowledged),
            "by_severity": severity_counts,
            "avg_recent_score": float(np.mean(recent)) if recent else 0.0,
            "max_recent_score": float(np.max(recent)) if recent else 0.0,
        }
